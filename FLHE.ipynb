{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fd2c0e-d0ba-481a-9883-c4825ad6b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5aef1bb-fe93-4b72-89d9-9651e9657e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PKNU\\anaconda3\\envs\\python39keras\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08287674-0fb4-4cc3-b5f0-d4ce3a27124b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c44e77-66d6-454c-a310-11ef84be50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4081c1d-36da-4e3c-9ae0-a03fe03fd44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d79851-eb62-48c3-8ec2-e2c1e90927e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b89c9d-fb6b-48a6-b2ca-9ea723e2f411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (0.41.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94941df5-0a3a-46bb-903f-faa06fb9e669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyfhel==2.3.1 in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: cython>=0.29.2 in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (from pyfhel==2.3.1) (3.0.10)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (from pyfhel==2.3.1) (1.26.4)\n",
      "Requirement already satisfied: setuptools>=45.0.0 in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (from pyfhel==2.3.1) (68.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyfhel==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d6b9a9-28db-46b2-92a1-3301c1f5d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.19\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51b701a5-91af-45ac-8310-f90f888adc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdae2b0-4135-411d-92b7-d88f0b5df177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6eaaba3-a4c2-4c81-ae55-5c95e3fa39ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pknu\\anaconda3\\envs\\python39keras\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4ef0f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np              \n",
    "import pandas as pd          \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score,\\\n",
    "    f1_score, accuracy_score, classification_report\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from FLPyfhelin import *\n",
    "from Pyfhel import Pyfhel, PyPtxt, PyCtxt\n",
    "import time\n",
    "\n",
    "train_path = 'image/Train'\n",
    "test_path = 'image/Test'\n",
    "#folder = 'image'\n",
    "batch_size = 32\n",
    "#num_client =2\n",
    "SCALE=1\n",
    "epoch=10\n",
    "input_size  = (int(256*SCALE), int(256*SCALE), 3)\n",
    "image_size  = (int(256*SCALE), int(256*SCALE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60a754db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pyfhel obj at 0x1bf9e5b66b0, [pk:Y, sk:Y, rtk:-, rlk:-, contx(p=65537, m=1024, base=2, sec=128, dig=64i.32f, batch=False)]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate and export public key, just need to run it once\n",
    "HE=gen_pk(s=128, m=1024)\n",
    "keys ={}\n",
    "keys['HE'] = HE\n",
    "keys['con'] = HE.to_bytes_context()\n",
    "keys['pk'] = HE.to_bytes_publicKey()\n",
    "keys['sk'] = HE.to_bytes_secretKey()\n",
    "    \n",
    "filename =  \"privatekey.pickle\"\n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump(keys, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a707604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Pyfhel obj at 0x1bf9ba8a050, [pk:Y, sk:Y, rtk:-, rlk:-, contx(p=65537, m=1024, base=2, sec=128, dig=64i.32f, batch=False)]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename =  \"privatekey.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "        key = pickle.load(handle)\n",
    "\n",
    "HE = key['HE']\n",
    "HE.from_bytes_context(key['con'])\n",
    "HE.from_bytes_publicKey(key['pk'])\n",
    "HE.from_bytes_secretKey(key['sk'])\n",
    "HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca5a15ba-9002-4e64-8961-36724126d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de270715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clients:  2\n",
      "Prepare dataset\n",
      "Found 60 validated image filenames belonging to 2 classes.\n",
      "Build main model\n",
      "WARNING:tensorflow:From C:\\Users\\PKNU\\anaconda3\\envs\\python39keras\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\PKNU\\anaconda3\\envs\\python39keras\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PKNU\\anaconda3\\envs\\python39keras\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Clients\n",
      "Found 90 validated image filenames belonging to 2 classes.\n",
      "Found 10 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\PKNU\\anaconda3\\envs\\python39keras\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7013 - accuracy: 0.4778\n",
      "Epoch 1: accuracy improved from -inf to 0.47778, saving model to weights\\client_1.ckpt\n",
      "3/3 [==============================] - 4s 937ms/step - loss: 0.7013 - accuracy: 0.4778 - val_loss: 0.6957 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.5000\n",
      "Epoch 2: accuracy improved from 0.47778 to 0.50000, saving model to weights\\client_1.ckpt\n",
      "3/3 [==============================] - 2s 698ms/step - loss: 0.6941 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5000\n",
      "Epoch 3: accuracy did not improve from 0.50000\n",
      "3/3 [==============================] - 2s 643ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5000\n",
      "Epoch 4: accuracy did not improve from 0.50000\n",
      "3/3 [==============================] - 2s 669ms/step - loss: 0.6921 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.5000\n",
      "Epoch 5: accuracy did not improve from 0.50000\n",
      "3/3 [==============================] - 2s 799ms/step - loss: 0.6919 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6895 - accuracy: 0.5000\n",
      "Epoch 6: accuracy did not improve from 0.50000\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 0.6895 - accuracy: 0.5000 - val_loss: 0.6956 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6855 - accuracy: 0.5000\n",
      "Epoch 7: accuracy did not improve from 0.50000\n",
      "3/3 [==============================] - 2s 637ms/step - loss: 0.6855 - accuracy: 0.5000 - val_loss: 0.6948 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.5333\n",
      "Epoch 8: accuracy improved from 0.50000 to 0.53333, saving model to weights\\client_1.ckpt\n",
      "3/3 [==============================] - 2s 780ms/step - loss: 0.6756 - accuracy: 0.5333 - val_loss: 0.6986 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.5556\n",
      "Epoch 9: accuracy improved from 0.53333 to 0.55556, saving model to weights\\client_1.ckpt\n",
      "3/3 [==============================] - 2s 674ms/step - loss: 0.6501 - accuracy: 0.5556 - val_loss: 0.7097 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.6667\n",
      "Epoch 10: accuracy improved from 0.55556 to 0.66667, saving model to weights\\client_1.ckpt\n",
      "3/3 [==============================] - 2s 704ms/step - loss: 0.6353 - accuracy: 0.6667 - val_loss: 0.8198 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Found 90 validated image filenames belonging to 2 classes.\n",
      "Found 10 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6718 - accuracy: 0.5222\n",
      "Epoch 1: accuracy improved from -inf to 0.52222, saving model to weights\\client_2.ckpt\n",
      "3/3 [==============================] - 3s 876ms/step - loss: 0.6718 - accuracy: 0.5222 - val_loss: 0.7354 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.5111\n",
      "Epoch 2: accuracy did not improve from 0.52222\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.6992 - accuracy: 0.5111 - val_loss: 0.7274 - val_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.5333\n",
      "Epoch 3: accuracy improved from 0.52222 to 0.53333, saving model to weights\\client_2.ckpt\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "3/3 [==============================] - 3s 766ms/step - loss: 0.6924 - accuracy: 0.5333 - val_loss: 0.6688 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.6556\n",
      "Epoch 4: accuracy improved from 0.53333 to 0.65556, saving model to weights\\client_2.ckpt\n",
      "3/3 [==============================] - 2s 685ms/step - loss: 0.6652 - accuracy: 0.6556 - val_loss: 0.6565 - val_accuracy: 0.8000 - lr: 3.0000e-04\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6513 - accuracy: 0.6444\n",
      "Epoch 5: accuracy did not improve from 0.65556\n",
      "3/3 [==============================] - 2s 748ms/step - loss: 0.6513 - accuracy: 0.6444 - val_loss: 0.6261 - val_accuracy: 0.9000 - lr: 3.0000e-04\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.5444\n",
      "Epoch 6: accuracy did not improve from 0.65556\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 0.6569 - accuracy: 0.5444 - val_loss: 0.5312 - val_accuracy: 0.9000 - lr: 3.0000e-04\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6409 - accuracy: 0.6111\n",
      "Epoch 7: accuracy did not improve from 0.65556\n",
      "3/3 [==============================] - 2s 693ms/step - loss: 0.6409 - accuracy: 0.6111 - val_loss: 0.5489 - val_accuracy: 0.8000 - lr: 3.0000e-04\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6142 - accuracy: 0.7222\n",
      "Epoch 8: accuracy improved from 0.65556 to 0.72222, saving model to weights\\client_2.ckpt\n",
      "3/3 [==============================] - 2s 652ms/step - loss: 0.6142 - accuracy: 0.7222 - val_loss: 0.5279 - val_accuracy: 0.9000 - lr: 3.0000e-04\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6087 - accuracy: 0.7222\n",
      "Epoch 9: accuracy did not improve from 0.72222\n",
      "3/3 [==============================] - 2s 651ms/step - loss: 0.6087 - accuracy: 0.7222 - val_loss: 0.5141 - val_accuracy: 0.8000 - lr: 3.0000e-04\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.7444\n",
      "Epoch 10: accuracy improved from 0.72222 to 0.74444, saving model to weights\\client_2.ckpt\n",
      "3/3 [==============================] - 2s 684ms/step - loss: 0.5915 - accuracy: 0.7444 - val_loss: 0.4989 - val_accuracy: 0.8000 - lr: 3.0000e-04\n",
      "Export client weights\n",
      "Time to encrypt weights: 96.3844997882843\n",
      "Time to export weights to pickle: 220.86058378219604\n",
      "Weights exported: Client 1\n",
      "Time to encrypt weights: 92.34733867645264\n",
      "Time to export weights to pickle: 257.5580303668976\n",
      "Weights exported: Client 2\n",
      "Total time to encrypt and export: 667.9502429962158\n",
      "Aggregate Weights\n",
      "Time to import: 61.020620346069336\n",
      "Time to import: 68.51294732093811\n",
      "Time to aggregate: 152.36540365219116\n",
      "Export Aggregate Weights\n",
      "Time to export weights to pickle: 252.27319359779358\n",
      "Time to import: 61.92769193649292\n",
      "Time to decrypt: 76.28805899620056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PKNU\\anaconda3\\envs\\python39keras\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run predictions on aggregated model\n",
      "2/2 [==============================] - 2s 322ms/step\n",
      "Run prepare confusion matrix\n"
     ]
    }
   ],
   "source": [
    "num_of_client_list = [2]\n",
    "prec_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "acc_list = []\n",
    "t =[]\n",
    "\n",
    "for j, num_client in enumerate(num_of_client_list):\n",
    "        print('Number of clients: ',num_client)\n",
    "        start = time.time()\n",
    "\n",
    "         \n",
    "        print('Prepare dataset')\n",
    "        df_train = prep_df(train_path,shuffle=True)\n",
    "        df_test = prep_df(test_path,shuffle=False)\n",
    "        test_ds = get_test_data(df_test,train_path)\n",
    "        \n",
    "        print('Build main model')\n",
    "        model = create_model()\n",
    "        model.save('main_model.hdf5')\n",
    "\n",
    "        print(\"Train Clients\")\n",
    "        train_clients(df_train, train_path, num_client,epoch)\n",
    "                \n",
    "        print(\"Export client weights\")\n",
    "        export_encrypted_clients_weights(num_client)\n",
    "                \n",
    "        print(\"Aggregate Weights\")\n",
    "        main_model_dict = aggregate_encrypted_weights(num_client)\n",
    "        filename=\"weights/aggregated.pickle\"\n",
    "        print(\"Export Aggregate Weights\")\n",
    "        export_weights(filename ,main_model_dict)\n",
    "                \n",
    "        agg_model = decrypt_import_weights(filename)\n",
    "\n",
    "        print(\"Run predictions on aggregated model\")\n",
    "        preds = agg_model.predict(test_ds,verbose=1)\n",
    "        predictions = preds.copy()\n",
    "        predictions = [np.argmax(x) for x in predictions]\n",
    "        \n",
    "        print(\"Run prepare confusion matrix\")\n",
    "        prec_list.append(precision_score(test_ds.classes, predictions,average='weighted'))\n",
    "        recall_list.append(recall_score(test_ds.classes, predictions,average='weighted'))\n",
    "        f1_list.append(f1_score(test_ds.classes, predictions,average='weighted'))\n",
    "        acc_list.append(accuracy_score(test_ds.classes, predictions))\n",
    "        end = time.time()\n",
    "        t.append(end-start)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46616942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.907240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.899554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  2\n",
       "Precision  0.907240\n",
       "Recall     0.900000\n",
       "F1 Score   0.899554\n",
       "Accuracy   0.900000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_list =[prec_list,recall_list,f1_list,acc_list]\n",
    "client = num_of_client_list\n",
    "idx=['Precision','Recall','F1 Score', 'Accuracy']\n",
    "\n",
    "df = pd.DataFrame(sum_list, index=idx, columns=client)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c175d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>1202.364557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                2\n",
       "Time  1202.364557"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_list =[t]\n",
    "client = num_of_client_list\n",
    "idx=['Time']\n",
    "\n",
    "df = pd.DataFrame(time_list, index=idx, columns=client)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed31f6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to export weights to pickle: 0.007844209671020508\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model=load_weights('1')\n",
    "encrypted_weights={}\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "        if model.layers[i].get_weights()!=[]:\n",
    "            encrypted =[]\n",
    "            weights = model.layers[i].get_weights()   \n",
    "\n",
    "            for j in range(len(weights)):\n",
    "                    array= weights[j]\n",
    "                    encrypted_weights['c_'+str(i)+'_'+str(j)]=array\n",
    "\n",
    "filename =  \"plainweights.pickle\"\n",
    "export_weights(filename, encrypted_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae054ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
